%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Jonathan Xue at 2021-12-01 15:18:21 -0600 


%% Saved with string encoding Unicode (UTF-8) 
%% SECTION: INDEXING
@article{Indexing,
	abstract = {The explosive growth in volume, velocity, and diversity of data produced by mobile devices and cloud applications has contributed to the abundance of data or `big data.' Available solutions for efficient data storage and management cannot fulfill the needs of such heterogeneous data where the amount of data is continuously increasing. For efficient retrieval and management, existing indexing solutions become inefficient with the rapidly growing index size and seek time and an optimized index scheme is required for big data. Regarding real-world applications, the indexing issue with big data in cloud computing is widespread in healthcare, enterprises, scientific experiments, and social networks. To date, diverse soft computing, machine learning, and other techniques in terms of artificial intelligence have been utilized to satisfy the indexing requirements, yet in the literature, there is no reported state-of-the-art survey investigating the performance and consequences of techniques for solving indexing in big data issues as they enter cloud computing. The objective of this paper is to investigate and examine the existing indexing techniques for big data. Taxonomy of indexing techniques is developed to provide insight to enable researchers understand and select a technique as a basis to design an indexing mechanism with reduced time and space consumption for BD-MCC. In this study, 48 indexing techniques have been studied and compared based on 60 articles related to the topic. The indexing techniques' performance is analyzed based on their characteristics and big data indexing requirements. The main contribution of this study is taxonomy of categorized indexing techniques based on their method. The categories are non-artificial intelligence, artificial intelligence, and collaborative artificial intelligence indexing methods. In addition, the significance of different procedures and performance is analyzed, besides limitations of each technique. In conclusion, several key future research topics with potential to accelerate the progress and deployment of artificial intelligence-based cooperative indexing in BD-MCC are elaborated on.},
	address = {Berlin, Heidelberg},
	author = {Gani, Abdullah and Siddiqa, Aisha and Shamshirband, Shahaboddin and Hanum, Fariza},
	date-modified = {2021-11-29 23:19:02 -0600},
	doi = {10.1007/s10115-015-0830-y},
	issn = {0219-1377},
	issue_date = {February 2016},
	journal = {Knowl. Inf. Syst.},
	month = feb,
	number = {2},
	numpages = {44},
	pages = {241--284},
	publisher = {Springer-Verlag},
	title = {A Survey on Indexing Techniques for Big Data: Taxonomy and Performance Evaluation},
	url = {https://doi.org/10.1007/s10115-015-0830-y},
	volume = {46},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1007/s10115-015-0830-y}}
	
@book{IndexingFundamentals,
    author = {Bhattacharya, Arnab},
    title = {Fundamentals of Database Indexing and Searching},
    year = {2014}, isbn = {1466582545},
    publisher = {Chapman \& Hall/CRC},
    edition = {1st},
    abstract = {Fundamentals of Database Indexing and Searching presents well-known database searching and indexing techniques. It focuses on similarity search queries, showing how to use distance functions to measure the notion of dissimilarity. After defining database queries and similarity search queries, the book organizes the most common and representative index structures according to their characteristics. The author first describes low-dimensional index structures, memory-based index structures, and hierarchical disk-based index structures. He then outlines useful distance measures and index structures that use the distance information to efficiently solve similarity search queries. Focusing on the difficult dimensionality phenomenon, he also presents several indexing methods that specifically deal with high-dimensional spaces. In addition, the book covers data reduction techniques, including embedding, various data transforms, and histograms. Through numerous real-world examples, this book explores how to effectively index and search for information in large collections of data. Requiring only a basic computer science background, it is accessible to practitioners and advanced undergraduate students.}}

@techreport{MainMemoryIndexStructures,
	author = {Lehman, Tobin J and Carey, Michael J},
	date-modified = {2021-11-29 23:15:27 -0600},
	institution = {University of Wisconsin-Madison Department of Computer Sciences},
	title = {A Study of Index Structures for a Main Memory Database Management System},
	year = {1985}}
	
@inproceedings{LearnedIndexing,
	abstract = {Indexes are models: a btree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term em learned indexes. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show that our learned indexes can have significant advantages over traditional indexes. More importantly, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work provides just a glimpse of what might be possible.},
	address = {New York, NY, USA},
	author = {Kraska, Tim and Beutel, Alex and Chi, Ed H. and Dean, Jeffrey and Polyzotis, Neoklis},
	booktitle = {Proceedings of the 2018 International Conference on Management of Data},
	date-modified = {2021-11-29 23:19:40 -0600},
	doi = {10.1145/3183713.3196909},
	isbn = {9781450347037},
	location = {Houston, TX, USA},
	numpages = {16},
	pages = {489--504},
	publisher = {Association for Computing Machinery},
	series = {SIGMOD '18},
	title = {The Case for Learned Index Structures},
	url = {https://doi.org/10.1145/3183713.3196909},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1145/3183713.3196909}}

@article{InvertedIndexing,
	abstract = {In a shared-nothing, distributed text retrieval system, queries are processed over an inverted index that is partitioned among a number of index servers. In practice, the index is either document-based or term-based partitioned. This choice is made depending on the properties of the underlying hardware infrastructure, query traffic distribution, and some performance and availability constraints. In query processing on retrieval systems that adopt a term-based index partitioning strategy, the high communication overhead due to the transfer of large amounts of data from the index servers forms a major performance bottleneck, deteriorating the scalability of the entire distributed retrieval system. In this work, to alleviate this problem, we propose a novel inverted index partitioning model that relies on hypergraph partitioning. In the proposed model, concurrently accessed index entries are assigned to the same index servers, based on the inverted index access patterns extracted from the past query logs. The model aims to minimize the communication overhead that will be incurred by future queries while maintaining the computational load balance among the index servers. We evaluate the performance of the proposed model through extensive experiments using a real-life text collection and a search query sample. Our results show that considerable performance gains can be achieved relative to the term-based index partitioning strategies previously proposed in literature. In most cases, however, the performance remains inferior to that attained by document-based partitioning.},
	address = {New York, NY, USA},
	articleno = {15},
	author = {Cambazoglu, B. Barla and Kayaaslan, Enver and Jonassen, Simon and Aykanat, Cevdet},
	date-modified = {2021-11-29 23:19:06 -0600},
	doi = {10.1145/2516633.2516637},
	issn = {1559-1131},
	issue_date = {September 2013},
	journal = {ACM Trans. Web},
	month = sep,
	number = {3},
	numpages = {23},
	publisher = {Association for Computing Machinery},
	title = {A Term-Based Inverted Index Partitioning Model for Efficient Distributed Query Processing},
	url = {https://doi.org/10.1145/2516633.2516637},
	volume = {7},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1145/2516633.2516637}}
	
% SECTION: QUERY PROCESSING
@article{QueryProcessing,
	abstract = {Various indexing methods of spatial data have come out after rigorous efforts put by many researchers for fast processing of spatial queries. Parallelizing spatial index building and query processing have become very popular for improving efficiency. The MapReduce framework provides a modern way of parallel processing. A MapReduce-based works for spatial queries consider the existing traditional spatial indexing for building spatial indexes in parallel. The majority of the spatial indexes implemented in MapReduce use R-Tree and its variants. Therefore, R-Tree and its variantbased traditional spatial indexes are thoroughly surveyed in the paper. The objective is to search for still less explored spatial indexing approaches, having the potential for parallelism in MapReduce. The review work also provides a detailed survey of MapReduce-based spatial query processing approaches - hierarchical indexed and packed key-value storage based spatial dataset. Both approaches use different data partitioning strategies for distributing data among cluster nodes and managing the partitioned dataset through different indexing. Finally, a number of parameters are selected for comparison and analysis of all the existing approaches in the literature.},
	address = {New York, NY, USA},
	author = {Singh, Hari and Bawa, Seema},
	date-modified = {2021-12-01 15:18:19 -0600},
	doi = {10.1145/3137586.3137590},
	issn = {0163-5808},
	issue_date = {June 2017},
	journal = {SIGMOD Rec.},
	month = sep,
	number = {2},
	numpages = {12},
	pages = {18--29},
	publisher = {Association for Computing Machinery},
	title = {A Survey of Traditional and MapReduce Based Spatial Query Processing Approaches},
	url = {https://doi.org/10.1145/3137586.3137590},
	volume = {46},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1145/3137586.3137590}}
	
@article{DbToaster,
	author = {Koch, Christoph and Ahmad, Yanif and Kennedy, Oliver and Nikolic, Milos and N{\"o}tzli, Andres and Lupei, Daniel and Shaikhha, Amir},
	date-modified = {2021-11-29 23:16:22 -0600},
	journal = {The VLDB Journal},
	number = {2},
	pages = {253--278},
	publisher = {Springer},
	title = {DBToaster: Higher-order Delta Processing for Dynamic, Frequently Fresh Views},
	volume = {23},
	year = {2014}}

@article{DbToaster2,
	abstract = {We present DBToaster, a novel query compilation framework for producing high performance compiled query executors that incrementally and continuously answer standing aggregate queries using in-memory views. DBToaster targets applications that require efficient main-memory processing of standing queries (views) fed by high-volume data streams, recursively compiling view maintenance (VM) queries into simple C++ functions for evaluating database updates (deltas). While today's VM algorithms consider the impact of single deltas on view queries to produce maintenance queries, we recursively consider deltas of maintenance queries and compile to thoroughly transform queries into code. Recursive compilation successively elides certain scans and joins, and eliminates significant query plan interpreter overheads.In this demonstration, we walk through our compilation algorithm, and show the significant performance advantages of our compiled executors over other query processors. We are able to demonstrate 1--3 orders of magnitude improvements in processing times for a financial application and a data warehouse loading application, both implemented across a wide range of database systems, including PostgreSQL, HSQLDB, a commercial DBMS 'A', the Stanford STREAM engine, and a commercial stream processor 'B'.},
	author = {Ahmad, Yanif and Koch, Christoph},
	doi = {10.14778/1687553.1687592},
	issn = {2150-8097},
	issue_date = {August 2009},
	journal = {Proc. VLDB Endow.},
	month = aug,
	number = {2},
	numpages = {4},
	pages = {1566--1569},
	publisher = {VLDB Endowment},
	title = {DBToaster: A SQL Compiler for High-Performance Delta Processing in Main-Memory Databases},
	url = {https://doi.org/10.14778/1687553.1687592},
	volume = {2},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.14778/1687553.1687592}}
	
@article{IVM-Algorithm,
    author = {Almazyad, Abdulaziz and Siddiqui, Mohammad Khubeb},
    year = {2010},
    month = {01},
    pages = {16},
    title = {Incremental View Maintenance: An Algorithmic Approach},
    volume = {Vol: 10},
    journal = {International Journal of Electrical \& Computer Sciences IJECS-IJENS}}
    
@article{InSitu,
	author = {Olma, Matthaios and Karpathiotakis, Manos and Alagiannis, Ioannis and Athanassoulis, Manos and Ailamaki, Anastasia},
	journal = {The VLDB Journal},
	number = {1},
	pages = {569--591},
	publisher = {Springer},
	title = {Adaptive partitioning and indexing for in situ query processing},
	volume = {29},
	year = {2020}}

@article{DeltaNoSQL,
    author = {Hu, Yong and Dessloch, Stefan},
    title = {Extracting Deltas from Column Oriented NoSQL Databases for Different Incremental Applications and Diverse Data Targets},
    year = {2014},
    issue_date = {September 2014},
    publisher = {Elsevier Science Publishers B. V.},
    address = {NLD},
    volume = {93},
    number = {C},
    issn = {0169-023X},
    url = {https://doi.org/10.1016/j.datak.2014.07.002},
    doi = {10.1016/j.datak.2014.07.002},
    abstract = {This paper describes the Change Data Capture (CDC) problems in the context of column-oriented NoSQL databases (CoNoSQLDBs). CDC is a term mostly used by ETL tools and data warehousing environments (DW) to depict a data processing of extracting data changes made at the data sources. Based on analyzing the impacts and constraints caused by the core features of CoNoSQLDBs, we propose a logical change data (delta) model and the corresponding delta representations which could work with different incremental applications and diverse data targets. Moreover, we present five feasible CDC approaches, i.e. Timestamp-based approach, Audit-column approach, Log-based approach, Trigger-based approach and Snapshot differential approach and indicate the performance winners under different circumstances.},
    journal = {Data Knowl. Eng.},
    month = sep,
    pages = {42–59},
    numpages = {18},
    keywords = {CoNoSQLDB, CDC approaches, Delta representations, Delta model}}
    
@article{10.1145/235968.233364,
author = {Colby, Latha S. and Griffin, Timothy and Libkin, Leonid and Mumick, Inderpal Singh and Trickey, Howard},
title = {Algorithms for Deferred View Maintenance},
year = {1996},
issue_date = {June 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/235968.233364},
doi = {10.1145/235968.233364},
abstract = {Materialized views and view maintenance are important for data warehouses, retailing, banking, and billing applications. We consider two related view maintenance problems: 1) how to maintain views after the base tables have already been modified, and 2) how to minimize the time for which the view is inaccessible during maintenance.Typically, a view is maintained immediately, as a part of the transaction that updates the base tables. Immediate maintenance imposes a significant overhead on update transactions that cannot be tolerated in many applications. In contrast, deferred maintenance allows a view to become inconsistent with its definition. A refresh operation is used to reestablish consistency. We present new algorithms to incrementally refresh a view during deferred maintenance. Our algorithms avoid a state bug that has artificially limited techniques previously used for deferred maintenance.Incremental deferred view maintenance requires auxiliary tables that contain information recorded since the last view refresh. We present three scenarios for the use of auxiliary tables and show how these impact per-transaction overhead and view refresh time. Each scenario is described by an invariant that is required to hold in all database states. We then show that, with the proper choice of auxiliary tables, it is possible to lower both per-transaction overhead and view refresh time.},
journal = {SIGMOD Rec.},
month = {jun},
pages = {469–480},
numpages = {12}}

@inproceedings{10.1145/223784.223849,
author = {Griffin, Timothy and Libkin, Leonid},
title = {Incremental Maintenance of Views with Duplicates},
year = {1995},
isbn = {0897917316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/223784.223849},
doi = {10.1145/223784.223849},
abstract = {We study the problem of efficient maintenance of materialized views that may contain duplicates. This problem is particularly important when queries against such views involve aggregate functions, which need duplicates to produce correct results. Unlike most work on the view maintenance problem that is based on an algorithmic approach, our approach is algebraic and based on equational reasoning. This approach has a number of advantages: it is robust and easily extendible to new language constructs, it produces output that can be used by query optimizers, and it simplifies correctness proofs.We use a natural extension of the relational algebra operations to bags (multisets) as our basic language. We present an algorithm that propagates changes from base relations to materialized views. This algorithm is based on reasoning about equivalence of bag-valued expressions. We prove that it is correct and preserves a certain notion of minimality that ensures that no unnecessary tuples are computed. Although it is generally only a heuristic that computing changes to the view rather than recomputing the view from scratch is more efficient, we prove results saying that under normal circumstances one should expect, the change propagation algorithm to be significantly faster and more space efficient than complete recomputing of the view. We also show that our approach interacts nicely with aggregate functions, allowing their correct evaluation on views that change.},
booktitle = {Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data},
pages = {328–339},
numpages = {12},
location = {San Jose, California, USA},
series = {SIGMOD '95}
}

@article{IVMWithDuplicates,
    author = {Griffin, Timothy and Libkin, Leonid},
    title = {Incremental Maintenance of Views with Duplicates},
    year = {1995},
    issue_date = {May 1995},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {24},
    number = {2},
    issn = {0163-5808},
    url = {https://doi.org/10.1145/568271.223849},
    doi = {10.1145/568271.223849},
    abstract = {We study the problem of efficient maintenance of materialized views that may contain duplicates. This problem is particularly important when queries against such views involve aggregate functions, which need duplicates to produce correct results. Unlike most work on the view maintenance problem that is based on an algorithmic approach, our approach is algebraic and based on equational reasoning. This approach has a number of advantages: it is robust and easily extendible to new language constructs, it produces output that can be used by query optimizers, and it simplifies correctness proofs.We use a natural extension of the relational algebra operations to bags (multisets) as our basic language. We present an algorithm that propagates changes from base relations to materialized views. This algorithm is based on reasoning about equivalence of bag-valued expressions. We prove that it is correct and preserves a certain notion of minimality that ensures that no unnecessary tuples are computed. Although it is generally only a heuristic that computing changes to the view rather than recomputing the view from scratch is more efficient, we prove results saying that under normal circumstances one should expect, the change propagation algorithm to be significantly faster and more space efficient than complete recomputing of the view. We also show that our approach interacts nicely with aggregate functions, allowing their correct evaluation on views that change.},
    journal = {SIGMOD Rec.},
    month = may,
    pages = {328–339},
    numpages = {12}}

@inproceedings{IDeferredVM,
    author = {Colby, Latha S. and Griffin, Timothy and Libkin, Leonid and Mumick, Inderpal Singh and Trickey, Howard},
    title = {Algorithms for Deferred View Maintenance},
    year = {1996},
    isbn = {0897917944},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/233269.233364},
    doi = {10.1145/233269.233364},
    abstract = {Materialized views and view maintenance are important for data warehouses, retailing, banking, and billing applications. We consider two related view maintenance problems: 1) how to maintain views after the base tables have already been modified, and 2) how to minimize the time for which the view is inaccessible during maintenance.Typically, a view is maintained immediately, as a part of the transaction that updates the base tables. Immediate maintenance imposes a significant overhead on update transactions that cannot be tolerated in many applications. In contrast, deferred maintenance allows a view to become inconsistent with its definition. A refresh operation is used to reestablish consistency. We present new algorithms to incrementally refresh a view during deferred maintenance. Our algorithms avoid a state bug that has artificially limited techniques previously used for deferred maintenance.Incremental deferred view maintenance requires auxiliary tables that contain information recorded since the last view refresh. We present three scenarios for the use of auxiliary tables and show how these impact per-transaction overhead and view refresh time. Each scenario is described by an invariant that is required to hold in all database states. We then show that, with the proper choice of auxiliary tables, it is possible to lower both per-transaction overhead and view refresh time.},
    booktitle = {Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data},
    pages = {469–480},
    numpages = {12},
    location = {Montreal, Quebec, Canada},
    series = {SIGMOD '96}}
    
@inproceedings{BatchIVM,
    author = {He, Hao and Xie, Junyi and Yang, Jun and Yu, Hai},
    title = {Asymmetric Batch Incremental View Maintenance},
    year = {2005},
    isbn = {0769522858},
    publisher = {IEEE Computer Society},
    address = {USA},
    url = {https://doi.org/10.1109/ICDE.2005.22},
    doi = {10.1109/ICDE.2005.22},
    abstract = {Incremental view maintenance has found a growing number of applications recently, including data warehousing, continuous query processing, publish/subscribe systems, etc. Batch processing of base table modifications, when applicable, can be much more efficient than processing individual modifications one at a time. In this paper, we tackle the problem of finding the most efficient batch incremental maintenance strategy under a refresh response time constraint; that is, at any point in time, the system, upon request, must be able to bring the view up to date within a specified amount of time. The traditional approach is to process all batched modifications relevant to the view whenever the constraint is violated. However, we observe that there often exists natural asymmetry among different components of the maintenance cost; for example,modifications on one base table might be cheaper to process than those on another base table because of some index. We exploit such asymmetries using an unconventional strategy that selectively processes modifications on some base tables while keeping batching others. We present a series of analytical results leading to the development of practical algorithms that approximate an "oracle algorithm" with perfect knowledge of the future. With experiments on a TPC-R database, we demonstrate that our strategy offers substantial performance gains over traditional deferred view maintenance techniques.},
    booktitle = {Proceedings of the 21st International Conference on Data Engineering},
    pages = {106–117},
    numpages = {12},
    series = {ICDE '05}}
    
@article{CDC-CoNoSQL,
    author = {Hu, Yong and Qu, Weiping},
    year = {2013},
    month = {01},
    pages = {587-598},
    title = {Efficiently Extracting Change Data from Column Oriented NoSQL Databases},
    volume = {21},
    isbn = {978-3-642-35472-4},
    doi = {10.1007/978-3-642-35473-1_58}}
    
@article{ObjectOriented-IVM,
    author = {Alhajj, Reda and Polat, Faruk},
    title = {Incremental View Maintenance in Object-Oriented Databases},
    year = {1998},
    issue_date = {Summer 1998},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {29},
    number = {3},
    issn = {0095-0033},
    url = {https://doi.org/10.1145/313310.313338},
    doi = {10.1145/313310.313338},
    abstract = {A database management system should support views to facilitate filtering of information in order to have only necessary and required information available to users with minimal delay. Although a lot of research efforts concentrated on views within the conventional relational model, much more effort is required when object-oriented models are considered. However, supporting views is only a step forward in achieving the purpose that requires improving the performance of the system by considering incremental maintenance of views instead of recomputing a view from scratch each time it is accessedIn this paper, we introduce a model that facilitates incremental maintenance of single-class-based object-oriented views by employing the deferred update mode that has proved to be more suitable for object-oriented databases in general. For that purpose, we categorize classes into base and brother classes corresponding to classes originally present in the database and those introduced as views, respectively. To each class, we add a modification list that keeps related modifications during different intervals. An interval starts with the creation or update of a view and ends with the creation or update of another view. A modification list is empty as long as no views depend on its class. Further, we introduce some algorithms that locate modifications done on related classes while trying to compute a given view incrementally. Finally, we give a theoretical justification showing that, in general, the introduced algorithms perform much better than doing computation from scratch each time a view is accessed.},
    journal = {SIGMIS Database},
    month = jun,
    pages = {52–64},
    numpages = {13},
    keywords = {object-oriented databases, base classes, views, modification lists, algorithms}}

% SECTION: Caching
@inproceedings{Caching,
	author = {Tamboli, Shakil and Patel, Smita Shukla},
	booktitle = {2015 International Conference on Pervasive Computing (ICPC)},
	doi = {10.1109/PERVASIVE.2015.7087016},
	pages = {1-6},
	title = {A survey on innovative approach for improvement in efficiency of caching technique for big data application},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1109/PERVASIVE.2015.7087016}}
	
@article{FlashStore,
	abstract = {We present FlashStore, a high throughput persistent key-value store, that uses flash memory as a non-volatile cache between RAM and hard disk. FlashStore is designed to store the working set of key-value pairs on flash and use one flash read per key lookup. As the working set changes over time, space is made for the current working set by destaging recently unused key-value pairs to hard disk and recycling pages in the flash store. FlashStore organizes key-value pairs in a log-structure on flash to exploit faster sequential write performance. It uses an in-memory hash table to index them, with hash collisions resolved by a variant of cuckoo hashing. The in-memory hash table stores compact key signatures instead of full keys so as to strike tradeoffs between RAM usage and false flash read operations.FlashStore can be used as a high throughput persistent key-value storage layer for a broad range of server class applications. We compare FlashStore with BerkeleyDB, an embedded key-value store application, running on hard disk and flash separately, so as to bring out the performance gain of FlashStore in not only using flash as a cache above hard disk but also in its use of flash aware algorithms. We use real-world data traces from two data center applications, namely, Xbox LIVE Primetime online multi-player game and inline storage deduplication, to drive and evaluate the design of FlashStore on traditional and low power server platforms. FlashStore outperforms BerkeleyDB by up to 60x on throughput (ops/sec), up to 50x on energy efficiency (ops/Joule), and up to 85x on cost efficiency (ops/sec/dollar) on the evaluated datasets.},
	author = {Debnath, Biplob and Sengupta, Sudipta and Li, Jin},
	doi = {10.14778/1920841.1921015},
	issn = {2150-8097},
	issue_date = {September 2010},
	journal = {Proc. VLDB Endow.},
	month = sep,
	number = {1--2},
	numpages = {12},
	pages = {1414--1425},
	publisher = {VLDB Endowment},
	title = {FlashStore: High Throughput Persistent Key-Value Store},
	url = {https://doi.org/10.14778/1920841.1921015},
	volume = {3},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.14778/1920841.1921015}}
	
@inproceedings{FalshKVStore,
    author = {Papagiannis, Anastasios and Saloustros, Giorgos and Gonz\'{a}lez-F\'{e}rez, Pilar and Bilas, Angelos},
    title = {An Efficient Memory-Mapped Key-Value Store for Flash Storage},
    year = {2018},
    isbn = {9781450360111},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3267809.3267824},
    doi = {10.1145/3267809.3267824},
    abstract = {Persistent key-value stores have emerged as a main component in the data access path of modern data processing systems. However, they exhibit high CPU and I/O overhead. Today, due to power limitations it is important to reduce CPU overheads for data processing.In this paper, we propose Kreon, a key-value store that targets servers with flash-based storage, where CPU overhead and I/O amplification are more significant bottlenecks compared to I/O randomness. We first observe that two significant sources of overhead in state-of-the-art key-value stores are: (a) The use of compaction in LSM-Trees that constantly perform merging and sorting of large data segments and (b) the use of an I/O cache to access devices, which incurs overhead even for data that reside in memory. To avoid these, Kreon performs data movement from level to level by performing partial instead of full data reorganization via the use of a full index per-level. In addition, Kreon uses memory-mapped I/O via a custom kernel path with Copy-On-Write.We implement Kreon as well as our custom memory-mapped I/O path in Linux and we evaluate Kreon using commodity SSDs with both small and large datasets (up to 6 billion keys). For a large dataset that stresses I/O, Kreon reduces CPU cycles/op by up to 5.8x, reduces I/O amplification for inserts by up to 4.61x, and increases insert ops/s by up to 5.3x, compared to RocksDB, a state-of-the-art key-value store that is broadly used today.},
    booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
    pages = {490–502},
    numpages = {13},
    keywords = {SSD, Memory-Mapped I/O, Copy-On-Write, mmap, Key-Value Stores, LSM-Tree},
    location = {Carlsbad, CA, USA},
    series = {SoCC '18}}
    
@inproceedings{BloomStore,  
    author={Lu, Guanlin and Nam, Young Jin and Du, David H. C.},  booktitle={2012 IEEE 28th Symposium on Mass Storage Systems and Technologies (MSST)},   title={BloomStore: Bloom-Filter based memory-efficient key-value store for indexing of data deduplication on flash},   year={2012},  volume={},  number={},  pages={1-11},  doi={10.1109/MSST.2012.6232390}}

@inproceedings{Oracle,
	author = {Pendse, Sukhada and Krishnaswamy, Vasudha and Kulkarni, Kartik and Li, Yunrui and Lahiri, Tirthankar and Raja, Vivekanandhan and Zheng, Jing and Girkar, Mahesh and Kulkarni, Akshay},
	booktitle = {2020 IEEE 36th International Conference on Data Engineering (ICDE)},
	organization = {IEEE},
	pages = {1570--1578},
	title = {Oracle Database In-Memory on Active Data Guard: Real-time Analytics on a Standby Database},
	year = {2020}}

@inproceedings{LazyViews,
	author = {Zhou, Jingren and Larson, Per-Ake and Elmongui, Hicham G},
	booktitle = {Proceedings of the 33rd international conference on Very large data bases},
	date-modified = {2021-11-29 23:16:53 -0600},
	pages = {231--242},
	title = {Lazy Maintenance of Materialized Views},
	year = {2007}}

@inproceedings{Memcached,
	author = {Fan, Bin and Andersen, David G and Kaminsky, Michael},
	booktitle = {10th $\{$USENIX$\}$ Symposium on Networked Systems Design and Implementation ($\{$NSDI$\}$ 13)},
	date-modified = {2021-11-29 23:17:13 -0600},
	pages = {371--384},
	title = {MemC3: Compact and Concurrent MemCache with Dumber Caching and Smarter Hashing},
	year = {2013}}
	
@inproceedings{DistibutedCaching,
	author = {Theel, Oliver and Pizka, Markus},
	booktitle = {Proceedings of the 32nd Annual Hawaii International Conference on Systems Sciences. 1999. HICSS-32. Abstracts and CD-ROM of Full Papers},
	date-modified = {2021-11-29 23:18:01 -0600},
	organization = {IEEE},
	pages = {1--2},
	title = {Distributed Caching and Replication},
	year = {1999}}

% SECTION: Data Interface
@inbook{VisualizationTechniques,
	address = {London},
	author = {Aigner, Wolfgang and Miksch, Silvia and Schumann, Heidrun and Tominski, Christian},
	pages = {147--254},
	publisher = {Springer London},
	title = {Survey of Visualization Techniques},
	year = {2011}}
	
@article{DirectManipulation,
	author = {Shneiderman},
	doi = {10.1109/MC.1983.1654471},
	journal = {Computer},
	number = {8},
	pages = {57-69},
	title = {Direct Manipulation: A Step Beyond Programming Languages},
	volume = {16},
	year = {1983},
	bdsk-url-1 = {https://doi.org/10.1109/MC.1983.1654471}}
	
@article{DataSplash,
author = {Woodruff, Allison and Olston, Chris and Aiken, Alexander and Chu, Michael and Ercegovac, Vuk and Lin, Mark and Spalding, Mybrid and Stonebraker, Michael},
year = {2001},
month = {10},
pages = {551-571},
title = {DataSplash: A Direct Manipulation Environment for Programming Semantic Zoom Visualizations of Tabular Data},
volume = {12},
journal = {J. Vis. Lang. Comput.},
doi = {10.1006/jvlc.2001.0219}}
	
@article{HealthcareDashboard,
	author = {Stadler, Jennifer G and Donlon, Kipp and Siewert, Jordan D and Franken, Tessa and Lewis, Nathaniel E},
	date-modified = {2021-11-29 23:16:41 -0600},
	journal = {Big data},
	number = {2},
	pages = {129--135},
	publisher = {Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA},
	title = {Improving the Efficiency and Ease of Healthcare Analysis Through Use of Data Visualization Dashboards},
	volume = {4},
	year = {2016}}
	
@article{CityDashboard,
    author = {Stehle, Samuel and Kitchin, Rob},
    year = {2019},
    month = {06},
    pages = {1-23},
    title = {Real-time and archival data visualisation techniques in city dashboards},
    volume = {34},
    journal = {International Journal of Geographical Information Science},
    doi = {10.1080/13658816.2019.1594823}}
    
@inproceedings{AttentionAwareDashboards,
    author = {Toreini, Peyman and Morana, Stefan},
    year = {2017},
    month = {05},
    pages = {},
    title = {Designing Attention-Aware Business Intelligence and Analytics Dashboards}}
    
@article{InteractiveVisualization,
    author={Godfrey, Parke and Gryz, Jarek and Lasek, Piotr},
    journal={IEEE Transactions on Knowledge and Data Engineering}, 
    title={Interactive Visualization of Large Data Sets}, 
    year={2016},
    volume={28},
    number={8},
    pages={2142-2157},
    doi={10.1109/TKDE.2016.2557324}}

% SECTION: MISC
@inproceedings{YCSB,
	abstract = {While the use of MapReduce systems (such as Hadoop) for large scale data analysis has been widely recognized and studied, we have recently seen an explosion in the number of systems developed for cloud data serving. These newer systems address "cloud OLTP" applications, though they typically do not support ACID transactions. Examples of systems proposed for cloud serving use include BigTable, PNUTS, Cassandra, HBase, Azure, CouchDB, SimpleDB, Voldemort, and many others. Further, they are being applied to a diverse range of applications that differ considerably from traditional (e.g., TPC-C like) serving workloads. The number of emerging cloud serving systems and the wide range of proposed applications, coupled with a lack of apples-to-apples performance comparisons, makes it difficult to understand the tradeoffs between systems and the workloads for which they are suited. We present the "Yahoo! Cloud Serving Benchmark" (YCSB) framework, with the goal of facilitating performance comparisons of the new generation of cloud data serving systems. We define a core set of benchmarks and report results for four widely used systems: Cassandra, HBase, Yahoo!'s PNUTS, and a simple sharded MySQL implementation. We also hope to foster the development of additional cloud benchmark suites that represent other classes of applications by making our benchmark tool available via open source. In this regard, a key feature of the YCSB framework/tool is that it is extensible--it supports easy definition of new workloads, in addition to making it easy to benchmark new systems.},
	address = {New York, NY, USA},
	author = {Cooper, Brian F. and Silberstein, Adam and Tam, Erwin and Ramakrishnan, Raghu and Sears, Russell},
	booktitle = {Proceedings of the 1st ACM Symposium on Cloud Computing},
	date-modified = {2021-11-29 23:19:16 -0600},
	doi = {10.1145/1807128.1807152},
	isbn = {9781450300360},
	location = {Indianapolis, Indiana, USA},
	numpages = {12},
	pages = {143--154},
	publisher = {Association for Computing Machinery},
	series = {SoCC '10},
	title = {Benchmarking Cloud Serving Systems with YCSB},
	url = {https://doi.org/10.1145/1807128.1807152},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1145/1807128.1807152}}

@article{Escrow,
	author = {O'Neil, Patrick E},
	date-modified = {2021-11-29 23:17:36 -0600},
	journal = {ACM Transactions on Database Systems (TODS)},
	number = {4},
	pages = {405--430},
	publisher = {ACM New York, NY, USA},
	title = {The Escrow Transactional Method},
	volume = {11},
	year = {1986}}

@article{DatabaseLock,
	author = {Molesky, Lory D and Ramamritham, Krithi},
	journal = {Jun},
	pages = {1--24},
	title = {Database Locking Protocols for Large-Scale Cache-Coherent Shared Memory Multiprocessors: Design, Implementation and Performance},
	volume = {6},
	year = {1995}}

@article{Cuckoo,
	author = {Pagh, Rasmus and Rodler, Flemming Friche},
	journal = {Journal of Algorithms},
	number = {2},
	pages = {122--144},
	publisher = {Elsevier},
	title = {Cuckoo hashing},
	volume = {51},
	year = {2004}}
	
@inproceedings{G-OLA,
    author = {Zeng, Kai and Agarwal, Sameer and Dave, Ankur and Armbrust, Michael and Stoica, Ion},
    title = {G-OLA: Generalized On-Line Aggregation for Interactive Analysis on Big Data},
    year = {2015},
    isbn = {9781450327589},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2723372.2735381},
    doi = {10.1145/2723372.2735381},
    abstract = {Nearly 15 years ago, Hellerstein, Haas and Wang proposed online aggregation (OLA), a technique that allows users to (1) observe the progress of a query by showing iteratively refined approximate answers, and (2) stop the query execution once its result achieves the desired accuracy. In this demonstration, we present G-OLA, a novel mini-batch execution model that generalizes OLA to support general OLAP queries with arbitrarily nested aggregates using efficient delta maintenance techniques. We have implemented G-OLA in FluoDB, a parallel online query execution framework that is built on top of the Spark cluster computing framework that can scale to massive data sets. We will demonstrate FluoDB on a cluster of 100 machines processing roughly 10TB of real-world session logs from a video-sharing website. Using an ad optimization and an A/B testing based scenario, we will enable users to perform real-time data analysis via web-based query consoles and dashboards.},
    booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
    pages = {913–918},
    numpages = {6},
    keywords = {online aggregation},
    location = {Melbourne, Victoria, Australia},
    series = {SIGMOD '15}}
    
@inproceedings{ErrorEstimation,
    author = {Agarwal, Sameer and Milner, Henry and Kleiner, Ariel and Talwalkar, Ameet and Jordan, Michael and Madden, Samuel and Mozafari, Barzan and Stoica, Ion},
    title = {Knowing When You're Wrong: Building Fast and Reliable Approximate Query Processing Systems},
    year = {2014},
    isbn = {9781450323765},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2588555.2593667},
    doi = {10.1145/2588555.2593667},
    abstract = {Modern data analytics applications typically process massive amounts of data on clusters of tens, hundreds, or thousands of machines to support near-real-time decisions.The quantity of data and limitations of disk and memory bandwidth often make it infeasible to deliver answers at interactive speeds. However, it has been widely observed that many applications can tolerate some degree of inaccuracy. This is especially true for exploratory queries on data, where users are satisfied with "close-enough" answers if they can come quickly. A popular technique for speeding up queries at the cost of accuracy is to execute each query on a sample of data, rather than the whole dataset. To ensure that the returned result is not too inaccurate, past work on approximate query processing has used statistical techniques to estimate "error bars" on returned results. However, existing work in the sampling-based approximate query processing (S-AQP) community has not validated whether these techniques actually generate accurate error bars for real query workloads. In fact, we find that error bar estimation often fails on real world production workloads. Fortunately, it is possible to quickly and accurately diagnose the failure of error estimation for a query. In this paper, we show that it is possible to implement a query approximation pipeline that produces approximate answers and reliable error bars at interactive speeds.},
    booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
    pages = {481–492},
    numpages = {12},
    keywords = {diagnostics, error estimation, approximate query processing},
    location = {Snowbird, Utah, USA},
    series = {SIGMOD '14}}
    
@inproceedings{IncrementalMaintenance,
    author = {Palpanas, Themistoklis and Sidle, Richard and Cochrane, Roberta and Pirahesh, Hamid},
    title = {Incremental Maintenance for Non-Distributive Aggregate Functions},
    year = {2002},
    publisher = {VLDB Endowment},
    abstract = {Incremental view maintenance is a well-known topic that has been addressed in the literature as well as implemented in database products. Yet, incremental refresh has been studied in depth only for a subset of the aggregate functions. In this paper we propose a general incremental maintenance mechanism that applies to all aggregate functions, including those that are not distributive over all operations. This class of functions is of great interest, and includes MIN/MAX, STDDEV, correlation, regression, XML constructor, and user defined functions. We optimize the maintenance of such views in two ways. First, by only recomputing the set of affected groups. Second, we extend the incremental infrastructure with work areas to support the maintenance of functions that are algebraic. We further optimize computation when multiple dissimilar aggregate functions are computed in the same view, and for special cases such as the maintenance of MIN/MAX, which are incrementally maintainable over insertions. We also address the important problem of incremental maintenance of views containing super-aggregates, including materialized OLAP cubes. We have implemented our algorithm on a prototype version of IBM DB2 UDB, and an experimental evaluation proves the validity of our approach.},
    booktitle = {Proceedings of the 28th International Conference on Very Large Data Bases},
    pages = {802–813},
    numpages = {12},
    location = {Hong Kong, China},
    series = {VLDB '02}}
    
@inproceedings{ApproximateQueryAnsweringSystem,
    author = {Acharya, Swarup and Gibbons, Phillip B. and Poosala, Viswanath and Ramaswamy, Sridhar},
    title = {The Aqua Approximate Query Answering System},
    year = {1999},
    isbn = {1581130848},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/304182.304581},
    doi = {10.1145/304182.304581},
    abstract = {Aqua is a system for providing fast, approximate answers to aggregate queries, which are very common in OLAP applications. It has been designed to run on top of any commercial relational DBMS. Aqua precomputes synopses (special statistical summaries) of the original data and stores them in the DBMS. It provides approximate answers along with quality guarantees by rewriting the queries to run on these synopses. Finally, Aqua keeps the synopses up-to-date as the database changes, using fast incremental maintenance techniques.},
    booktitle = {Proceedings of the 1999 ACM SIGMOD International Conference on Management of Data},
    pages = {574–576},
    numpages = {3},
    location = {Philadelphia, Pennsylvania, USA},
    series = {SIGMOD '99}}

% SECTION: Guides
@online{Docker,
	title = {Docker},
	url = {https://docs.docker.com/},
	bdsk-url-1 = {https://docs.docker.com/}}

@online{MySQL,
	title = {MySQL},
	url = {https://dev.mysql.com/},
	bdsk-url-1 = {https://dev.mysql.com/}}

% TODO
@inproceedings{InteractiveExplorationIndexing,
    author = {Zoumpatianos, Kostas and Idreos, Stratos and Palpanas, Themis},
    title = {Indexing for Interactive Exploration of Big Data Series},
    year = {2014},
    isbn = {9781450323765},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2588555.2610498},
    doi = {10.1145/2588555.2610498},
    abstract = {Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available, which is not currently possible with the state-of-the-art indexing methods and for very large data series collections. In this paper, we present the first adaptive indexing mechanism, specifically tailored to solve the problem of indexing and querying very large data series collections. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. We present a detailed design and evaluation of adaptive data series indexing over both synthetic data and real-world workloads. The results show that our approach can gracefully handle large data series collections, while drastically reducing the data to query delay: by the time state-of-the-art indexing techniques finish indexing 1 billion data series (and before answering even a single query), adaptive data series indexing has already answered $3*10^5$ queries.},
    booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
    pages = {1555–1566},
    numpages = {12},
    keywords = {adaptive indexing, data-series, nearest neighbor, similarity search, adaptive data-series index},
    location = {Snowbird, Utah, USA},
    series = {SIGMOD '14}}
    
@article{GroupCollab,
    author = {Dorohonceanu, Bogdan and Sletterink, Boi and Marsic, Ivan},
    year = {1999},
    month = {10},
    pages = {},
    title = {A Novel User Interface for Group Collaboration}}
    
@article{MultimodalInterface,
    author = {Cohen, Philip and Chen, Liang and Clow, Josh and Johnston, Michael and Mcgee, David and Pittman, Jay and Smith, Ira},
    year = {2003},
    month = {08},
    pages = {},
    title = {QuickSet: A Multimodal Interface for Distributed Interactive Simulation}}
    
@inproceedings{ADS,
    author = {Zoumpatianos, Kostas and Idreos, Stratos and Palpanas, Themis},
    title = {Indexing for Interactive Exploration of Big Data Series},
    year = {2014},
    isbn = {9781450323765},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2588555.2610498},
    doi = {10.1145/2588555.2610498},
    abstract = {Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available, which is not currently possible with the state-of-the-art indexing methods and for very large data series collections. In this paper, we present the first adaptive indexing mechanism, specifically tailored to solve the problem of indexing and querying very large data series collections. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. We present a detailed design and evaluation of adaptive data series indexing over both synthetic data and real-world workloads. The results show that our approach can gracefully handle large data series collections, while drastically reducing the data to query delay: by the time state-of-the-art indexing techniques finish indexing 1 billion data series (and before answering even a single query), adaptive data series indexing has already answered $3*10^5$ queries.},
    booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
    pages = {1555–1566},
    numpages = {12},
    keywords = {data-series, nearest neighbor, adaptive data-series index, adaptive indexing, similarity search},
    location = {Snowbird, Utah, USA},
    series = {SIGMOD '14}}